# ğŸ“ Academic Integrity Risk Engine

An **explainable AI system** that detects **abnormal online exam behavior** using unsupervised machine learning, graph-based similarity analysis, and ethical risk scoring to support human review without making direct accusations.

---

## ğŸ“Œ Problem Statement

With the rapid growth of online examinations, ensuring academic integrity at scale has become a major challenge. Traditional online proctoring solutions are often intrusive, costly, and difficult to scale, while automated cheating detection systems risk false accusations and ethical concerns.

In real-world scenarios, labeled cheating data is rarely available, making supervised approaches impractical. There is a strong need for an **ethical, explainable, and scalable AI-based solution** that can assist institutions without replacing human judgment.

---

## ğŸ¯ Solution Overview

The **Academic Integrity Risk Engine** models **normal exam-taking behavior** and identifies **unusual behavioral patterns** using unsupervised learning.  
Instead of labeling students as cheaters, the system assigns:

- **Risk Score (0â€“100)**
- **Risk Level (Low / Medium / High)**
- **Explainable Reasons** for the risk
- **Confidence Score**
- **Behavioral Trends across multiple exams**

The system is designed strictly as a **decision-support tool**, ensuring that final decisions remain with human reviewers.

---

## ğŸš€ Key Features

- **Unsupervised Anomaly Detection** using Isolation Forest  
- **Behavioral Clustering** with DBSCAN  
- **Graph-Based Similarity Analysis** to identify potential collusion groups  
- **Explainable AI** with human-readable risk explanations  
- **Adaptive Risk Thresholds** based on exam-wide behavior  
- **Confidence-Aware Risk Scoring**  
- **Multi-Exam Risk Trend Analysis**  
- **Ethical, Human-in-the-Loop Design**  
- **Interactive Streamlit Dashboard** for visualization and analysis  

---

## ğŸ§  System Architecture
```text
Data Ingestion
      â†“
Feature Engineering
      â†“
Statistical Analysis
      â†“
Clustering & Anomaly Detection
      â†“
Graph-Based Similarity Analysis
      â†“
Risk Scoring Engine
      â†“
Explainability & Confidence Estimation
      â†“
Trend Analysis
      â†“
Dashboard Visualization



---

## ğŸ›  Tech Stack

- **Programming Language:** Python  
- **Data Processing:** Pandas, NumPy  
- **Machine Learning:** Scikit-learn  
- **Graph Analysis:** NetworkX  
- **Visualization & UI:** Streamlit  
- **ML Paradigm:** Unsupervised Learning  

---

## ğŸ“‚ Project Structure

academic-integrity-risk-engine/
â”‚
â”œâ”€â”€ src/ # Core ML & logic modules
â”œâ”€â”€ data/ # Raw, processed, and final datasets
â”œâ”€â”€ app/ # Streamlit dashboard
â”œâ”€â”€ main.py # End-to-end ML pipeline
â”œâ”€â”€ requirements.txt # Project dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## â–¶ï¸ How to Run Locally

### 1ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run the ML Pipeline
python main.py

4ï¸âƒ£ Launch the Dashboard
streamlit run app/dashboard.py

ğŸ“Š Dashboard Features

The Streamlit dashboard allows users to:

View individual risk scores and risk levels

Understand why a student is flagged

Compare a studentâ€™s behavior with the population

Analyze risk trends over time

Explore similarity and community-based patterns

âš ï¸ Ethical Considerations

This system does NOT label students as cheaters

Outputs are risk indicators, not final decisions

Designed to support human-in-the-loop review

Focuses on fairness, transparency, and explainability

Ethical AI principles were a core design goal throughout this project.
